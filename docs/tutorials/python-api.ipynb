{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Python API\n",
    "\n",
    "In this tutorial you will learn how to use *fairly* as a Python package to clone, create and upload datasets to research data repositories.\n",
    "\n",
    "If you haven not done so, [install the fairly package.](../installation.rst)\n",
    "\n",
    "## Cloning a dataset\n",
    "\n",
    "The Python API provides the flexibility to explore the metadata of a `remote dataset` before downloading it. A `remote` dataset is any dataset which is not stored locally. \n",
    "\n",
    "1. In a python script, import the `fairly` package and open a remote dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairly\n",
    "\n",
    "# Open a remote dataset\n",
    "dataset = fairly.dataset(\"doi:10.4121/21588096.v1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You can now explore the metadata of the dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '21588096', 'version': '1'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://data.4tu.nl/datasets/a37120e2-96db-48e4-bd65-a54b970bc4fe/1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset.size)\n",
    "\n",
    "# number of files\n",
    "len(dataset.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata({'authors': [Person({'fullname': 'Stefan Nielsen', 'orcid_id': '0000-0002-9214-2932', 'figshare_id': 12882551})], 'keywords': ['Earthquakes', 'artificial neural network', 'precursor'], 'description': '<p>These are the accuracy results for the whole dataset A and B together. This is a second batch (2/2) of cycles where network was trained, tested and verified 50 times with different combinations of test, train and verification groups. There is a first batch of 50 in a separate file</p>', 'license': {'id': 2, 'name': 'CC0', 'url': 'https://creativecommons.org/publicdomain/zero/1.0/'}, 'title': 'Earthquake Precursors detected by convolutional neural network', 'doi': '10.4121/21588096.v1', 'type': 'dataset', 'access_type': 'open', 'custom_fields': {'Time coverage': '2012-2022', 'Publisher': '4TU.ResearchData', 'Organizations': 'University of Durham, Department of Earth Sciences.', 'Geolocation Longitude': '138.204', 'Geolocation Latitude': '36.546', 'Geolocation': 'Japan and surrounding area', 'Format': '*.py, *.csv, *.txt'}, 'categories': [13555], 'online_date': '2022-11-24T07:50:39'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# complete metadata\n",
    "dataset.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  You can save the dataset's metadata to a file to a local directory as follows. The directory will be created if it does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store dataset locally (i.e. clone dataset)\n",
    "local_dataset = dataset.store(\"./cloned-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a local dataset\n",
    "\n",
    "A `local dataset`` is a dataset which is stored locally. When creating our own dataset, we used a local dataset.\n",
    "\n",
    "1. Initialize a new dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairly\n",
    "\n",
    "# Initialize a local dataset\n",
    "dataset = fairly.init_dataset(\"./local-dataset\") # path is created if it does not exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set the dataset's metadata attributes by passing a list of attribute names and values to a local dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_metadata(\n",
    "    title=\"My first dataset\",\n",
    "    kewords=[ \"fairly\", \"python\", \"api\" ],\n",
    "    authors=[ \"0000-0002-0516-185X\",\n",
    "             { \"name\": \"Jane\", \"surname\": \"Doe\" }\n",
    "             ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata attributes can be passed one by one as follows\n",
    "dataset.metadata[\"license\"] = \"CC-BY-4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Add files and folders to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.includes.extend([ \n",
    "    \"README\", \n",
    "    \"*.csv\",\n",
    "     \"train/*.jpg\" \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. To save values to the dataset's attributes to the `manifest.yaml` file, we must call the `save()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save changes and update manifest.yaml\n",
    "dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading a dataset\n",
    "\n",
    "To upload a dataset to a research data repository, we must first register an access token for an account in the data repository. Check the tutorial on the [JupyterLab extension](./jupyterlab.rst) to learn how to register an access token.\n",
    "\n",
    "Once you have registered an access token, you can upload a dataset with a single command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset to data repository\n",
    "remote_dataset = dataset.upload('zenodo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing changes to a data repository\n",
    "\n",
    "After uploading a dataset to a data repository, you can use the `push` command to push changes to the dataset's metadata and files and update the data repository. The `push` method automatically finds the remote version of a dataset from the information available in the *manifest* file. It also updates the remote metadata, if any metadata fields are modified locally.\n",
    "\n",
    "> To be able to push updates to an existing dataset in a repository, you need to have write access to the dataset. For most of the repositories this requires you to be the owner of the dataset.\n",
    "> Most data repositories prevent updates if a dataset is \"published\" (i.e. editing is limited to datasets that are not yet published).\n",
    "\n",
    "### Changing metadata in a dataset\n",
    "\n",
    "For example, to update the *title* of a dataset for which you have a local copy, you can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = fairly.dataset(\"./local-dataset\")\n",
    "ds.metadata[\"title\"] = \"New title\"\n",
    "ds.save_metadata() # save changes to manifest.yaml\n",
    "\n",
    "ds.push() # push changes to data repository to update an existing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing files in a dataset\n",
    "\n",
    "You can add, remove, or modify files in a local dataset as you wish. If file inclusion or exclusion rules are defined using patterns (e.g. `'*.txt'`), then fairly automatically identifies added, removed, or modified files. Otherwise, you need to explicitly indicate what needs to be *included* or *excluded*. Use the `includes.append` and `excludes.append` methods to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include a new file or directory\n",
    "ds.includes.append(\"new file.txt\")\n",
    "\n",
    "# remove a file or directory\n",
    "ds.excludes.append(\"old file.txt\")\n",
    "\n",
    "ds.save() # save changes to manifest.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the changes are saved to the  *manifest file*, the remote version can be updated by calling the `push` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.push() # push changes to data repository "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the Fairly Python API, check the [API reference](../api/fairly.rst)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
